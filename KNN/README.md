# K-Nearest Neighbors (KNN) - Classification & Regression

This project includes both classification and regression implementations of the **K-Nearest Neighbors (KNN)** algorithm using real-world datasets.

---

## âœ… Classification

**Dataset:** `diabetes.csv`  
**Objective:** Predict whether a person has diabetes based on diagnostic features.

**Notebook:** `KNN_Classification.ipynb`

---

## âœ… Regression

**Dataset:** `Housing.csv`  
**Objective:** Predict house prices based on various features using KNN.

**Notebook:** `KNN_Regression.ipynb`

---

## ðŸ“š Theory Recap

### ðŸ“Œ KNN Basics:
- Lazy learner algorithm
- Non-parametric, instance-based learning
- Classifies a new instance based on a majority vote or average of k-nearest neighbors

### ðŸ“Œ Distance Metric:
- Euclidean Distance (most commonly used):  
\\[
\\text{Distance}(p, q) = \\sqrt{\\sum (p_i - q_i)^2}
\\]

### ðŸ“Œ Classification:
- Majority voting of neighbors

### ðŸ“Œ Regression:
- Mean of nearest neighbors' target values

---

## ðŸ§  Parameters:
- `n_neighbors`: Number of nearest neighbors to use
- `weights`: Uniform or distance
- `metric`: Distance measure (default: 'minkowski')

---

## ðŸ“¦ Requirements

```bash
pip install -r requirements.txt
