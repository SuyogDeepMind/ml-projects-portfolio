# Ridge Regression

This project demonstrates Ridge Regression, a regularized linear regression algorithm, applied on a sample dataset. Ridge Regression helps to reduce model complexity and prevent overfitting by adding L2 penalty to the loss function.

## 📌 Key Concepts Covered
- Bias-Variance Tradeoff
- L2 Regularization
- Coefficient shrinkage
- Hyperparameter tuning with alpha
- Model evaluation using R² Score and RMSE

## 🛠️ Technologies Used
- Python
- NumPy
- Pandas
- Scikit-learn
- Matplotlib
- Seaborn

## 📁 Files
- `Ridge_Regression.ipynb`: Jupyter notebook with full code and explanations
- `README.md`: Project documentation
- `requirements.txt`: Dependencies

## 🚀 How to Run
1. Clone the repository or download the notebook
2. Install dependencies using `pip install -r requirements.txt`
3. Run the notebook in Jupyter or any other notebook environment

## 📊 Output
The model demonstrates how Ridge regression reduces overfitting by controlling the magnitude of coefficients using L2 penalty, and compares performance with simple linear regression.

---

### Author
Suyog Manke
